import os
import json
from typing import List, Dict, Optional
from pathlib import Path



def extract_text_from_json(json_path: str) -> str:
    """
    Extract text content from JSON files supporting various structures.
    
    Args:
        json_path: Path to the JSON file
        
    Returns:
        str: Extracted text content
    """
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        extracted_text = ""
        
        # Handle dictionary structure (most common)
        if isinstance(data, dict):
            # Extract main content fields
            for field in ['content', 'text', 'description']:
                if field in data and data[field]:
                    extracted_text += f"{data[field]}\n\n"
            
            # Extract from data array (FAQ structure)
            if 'data' in data and isinstance(data['data'], list):
                for item in data['data']:
                    if isinstance(item, dict):
                        # Extract question and answer from FAQ
                        if 'question' in item and 'answer' in item:
                            extracted_text += f"Q: {item['question']}\n"
                            extracted_text += f"A: {item['answer']}\n\n"
                        # Extract other text fields
                        for field in ['content', 'text']:
                            if field in item and item[field]:
                                extracted_text += f"{item[field]}\n\n"
            
            # Extract metadata notes
            if 'metadata' in data and isinstance(data['metadata'], dict):
                metadata = data['metadata']
                if 'notes' in metadata and metadata['notes']:
                    extracted_text += f"Notes: {metadata['notes']}\n\n"
        
        # Handle array structure
        elif isinstance(data, list):
            for item in data:
                if isinstance(item, dict):
                    for field in ['content', 'text', 'description']:
                        if field in item and item[field]:
                            extracted_text += f"{item[field]}\n\n"
        
        return extracted_text.strip()
        
    except Exception as e:
        print(f"Error extracting text from JSON {json_path}: {e}")
        return ""

def extract_text_from_jsonl(jsonl_path: str) -> str:
    """
    Extract text content from JSONL (JSON Lines) files.
    Each line contains a separate JSON object with content and metadata.
    
    Args:
        jsonl_path: Path to the JSONL file
        
    Returns:
        str: Extracted text content from all lines
    """
    try:
        extracted_text = ""
        
        with open(jsonl_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    data = json.loads(line)
                    
                    if isinstance(data, dict):
                        # Extract main content
                        if 'content' in data and data['content']:
                            extracted_text += f"{data['content']}\n\n"
                        
                        # Extract alternative text field
                        if 'text' in data and data['text']:
                            extracted_text += f"{data['text']}\n\n"
                        
                        # Extract metadata information
                        if 'metadata' in data and isinstance(data['metadata'], dict):
                            metadata = data['metadata']
                            
                            # Add slide context for presentation files
                            if 'slide_number' in metadata:
                                extracted_text += f"--- Slide {metadata['slide_number']} ---\n"
                            
                            # Extract and clean speaker notes
                            if 'notes' in metadata and metadata['notes']:
                                # Clean up common artifacts from notes
                                notes = str(metadata['notes']).strip()
                                notes = notes.replace('Generated by Copilot\n\n', '')
                                notes = notes.replace('\u000b', ' ')  # Replace vertical tabs
                                notes = notes.replace('______', '')  # Remove underscores
                                
                                if notes:
                                    extracted_text += f"Speaker Notes: {notes}\n\n"
                
                except json.JSONDecodeError as e:
                    print(f"Warning: Invalid JSON on line {line_num} in {jsonl_path}: {e}")
                    continue
        
        return extracted_text.strip()
        
    except Exception as e:
        print(f"Error extracting text from JSONL {jsonl_path}: {e}")
        return ""


def extract_text_from_pptx(pptx_path: str) -> str:
    """
    Extract text content from PPTX files using python-pptx and OCR when available.
    
    Args:
        pptx_path: Path to the PPTX file
        
    Returns:
        str: Extracted text content from slides and images
    """
    try:
        # Try to import required libraries
        from pptx import Presentation
        
        # Initialize OCR processor if available
        ocr_processor = None
        try:
            from pptx_processor import PPTXProcessor
            from vlm_processor import HybridVLMProcessor
            from config import PPTX_PROCESSING
            from logging_config import setup_clean_logging
            
            # Initialize clean logging
            setup_clean_logging()
            
            if PPTX_PROCESSING.get('use_ocr', False) or PPTX_PROCESSING.get('use_vlm', False):
                ocr_processor = PPTXProcessor()
        except ImportError:
            pass  # OCR/VLM not available, continue with basic text extraction
        except Exception:
            pass  # OCR/VLM initialization failed, continue with basic text extraction
        
        # Extract basic text content
        presentation = Presentation(pptx_path)
        all_text = []
        
        for slide_num, slide in enumerate(presentation.slides, 1):
            slide_content = []
            
            # Extract text from shapes
            for shape in slide.shapes:
                if hasattr(shape, 'text') and shape.text.strip():
                    slide_content.append(shape.text.strip())
            
            # Extract notes
            if slide.notes_slide and slide.notes_slide.notes_text_frame:
                notes_text = slide.notes_slide.notes_text_frame.text.strip()
                if notes_text:
                    slide_content.append(f"Speaker Notes: {notes_text}")
            
            # Add slide content
            if slide_content:
                slide_text = f"--- Slide {slide_num} ---\n" + "\n".join(slide_content) + "\n"
                all_text.append(slide_text)
        
        # Add OCR content if processor is available
        if ocr_processor:
            try:
                ocr_result = ocr_processor.process_pptx_file(pptx_path)
                
                if 'ocr_results' in ocr_result:
                    ocr_content = []
                    for result in ocr_result['ocr_results']:
                        if result.get('extracted_text', '').strip():
                            slide_num = result['metadata']['slide_number']
                            confidence = result.get('confidence', 0)
                            text = result['extracted_text']
                            
                            # Check for partner-related content
                            partner_indicators = ['partner', 'partnership', 'alliance']
                            if any(indicator in text.lower() for indicator in partner_indicators):
                                ocr_text = f"--- Slide {slide_num} (OCR - Partners, confidence: {confidence:.1f}) ---\n{text}\n"
                            else:
                                ocr_text = f"--- Slide {slide_num} (OCR, confidence: {confidence:.1f}) ---\n{text}\n"
                            
                            ocr_content.append(ocr_text)
                    
                    if ocr_content:
                        all_text.append("=== OCR Extracted Content ===\n" + "\n".join(ocr_content))
                        
            except Exception:
                pass  # OCR processing failed, continue with basic text only
        
        return "\n".join(all_text).strip()
        
    except ImportError:
        print(f"python-pptx not available. Cannot process {pptx_path}")
        return ""
    except Exception as e:
        print(f"Error extracting text from PPTX {pptx_path}: {e}")
        return ""


def load_documents_from_folder(data_folder: str, single_file_path: str = None) -> List[Dict[str, str]]:
    """
    Load and extract text content from JSON, JSONL, and PPTX files in the specified folder.
    Enhanced version supports PPTX files with OCR and VLM processing when available.
    
    Args:
        data_folder: Path to folder containing supported files
        single_file_path: Optional specific file path to process instead of entire folder
        
    Returns:
        List of documents with 'text' and 'source' fields
    """
    documents = []
    
    # Validate data folder exists
    if not os.path.exists(data_folder):
        print(f"ERROR: Data folder '{data_folder}' not found.")
        print("Please create the folder and add JSON/JSONL files with your data.")
        return documents

    # Determine which files to process
    files_to_process = []
    if single_file_path:
        if os.path.exists(single_file_path):
            files_to_process.append(single_file_path)
        else:
            print(f"ERROR: Single file '{single_file_path}' not found.")
            return documents
    else:
        # Collect all files from data folder
        for root, _, files in os.walk(data_folder):
            for file_name in files:
                file_path = os.path.join(root, file_name)
                files_to_process.append(file_path)

    # Process JSON, JSONL, and PPTX files
    supported_extensions = {'.json', '.jsonl', '.pptx'}
    supported_files = [f for f in files_to_process 
                      if Path(f).suffix.lower() in supported_extensions]
    
    if not supported_files:
        print("WARNING: No JSON, JSONL, or PPTX files found in data folder.")
        return documents

    # Sort files by processing priority (from config)
    try:
        from config import FILE_PRIORITY
        supported_files.sort(key=lambda f: FILE_PRIORITY.get(Path(f).suffix.lower(), 99))
    except ImportError:
        pass  # Use default order if config not available
    
    print(f"Processing {len(supported_files)} supported files (JSON/JSONL/PPTX)...")
    
    # Extract text from each file
    for file_path in supported_files:
        try:
            file_extension = Path(file_path).suffix.lower()
            extracted_text = ""
            processing_method = file_extension.replace('.', '')
            
            if file_extension == ".json":
                extracted_text = extract_text_from_json(file_path)
            elif file_extension == ".jsonl":
                extracted_text = extract_text_from_jsonl(file_path)
            elif file_extension == ".pptx":
                extracted_text = extract_text_from_pptx(file_path)
                processing_method = "pptx_enhanced"
            
            # Only add documents with content
            if extracted_text.strip():
                documents.append({
                    "text": extracted_text,
                    "source": file_path,
                    "processing_method": processing_method
                })
                print(f"Loaded: {os.path.basename(file_path)} ({processing_method})")
            else:
                print(f"Empty content: {os.path.basename(file_path)}")
                
        except Exception as e:
            print(f"Error processing {os.path.basename(file_path)}: {e}")
    
    print(f"Successfully loaded {len(documents)} documents.")
    return documents


def check_pptx_capabilities() -> Dict[str, bool]:
    """
    Check which PPTX processing capabilities are available.
    
    Returns:
        Dictionary indicating available features
    """
    capabilities = {
        'pptx_basic': False,
        'pptx_ocr': False,
        'vlm_processing': False,
        'hybrid_processing': False
    }
    
    # Check basic PPTX support
    try:
        from pptx import Presentation
        capabilities['pptx_basic'] = True
    except ImportError:
        print("python-pptx not installed. PPTX processing disabled.")
    
    # Check OCR support
    try:
        from pptx_processor import PPTXProcessor
        import pytesseract
        from PIL import Image
        capabilities['pptx_ocr'] = True
    except ImportError as e:
        print(f"OCR dependencies not available: {e}")
    
    # Check VLM support
    try:
        from vlm_processor import HybridVLMProcessor
        import google.generativeai as genai
        from config import GEMINI_API_KEY
        if GEMINI_API_KEY and GEMINI_API_KEY != "YOUR_GEMINI_API_KEY":
            capabilities['vlm_processing'] = True
    except ImportError as e:
        print(f"VLM dependencies not available: {e}")
    
    capabilities['hybrid_processing'] = capabilities['pptx_ocr'] and capabilities['vlm_processing']
    
    return capabilities


if __name__ == "__main__":
    # Test the enhanced data loader
    print("Enhanced Data Loader - Capability Check")
    print("=" * 50)
    
    capabilities = check_pptx_capabilities()
    for feature, available in capabilities.items():
        status = "Available" if available else "Not Available"
        print(f"{feature}: {status}")
    
    print("\nTesting document loading...")
    # You can add test folder path here if needed
    test_folder = "./data"
    if os.path.exists(test_folder):
        docs = load_documents_from_folder(test_folder)
        print(f"Found {len(docs)} documents in test folder")
    else:
        print("No test folder found. Enhanced data loader ready for use.")